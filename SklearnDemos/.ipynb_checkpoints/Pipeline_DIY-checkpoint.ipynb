{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "介绍了自定义转换器和工作流水线<br>\n",
    "对于基于sklearn的各类estimator和transformer，其都将转换为ndarray，从而丧失dataframe的index和columns信息<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>longitude</th>\n",
       "      <th>latitude</th>\n",
       "      <th>housing_median_age</th>\n",
       "      <th>total_rooms</th>\n",
       "      <th>total_bedrooms</th>\n",
       "      <th>population</th>\n",
       "      <th>households</th>\n",
       "      <th>median_income</th>\n",
       "      <th>median_house_value</th>\n",
       "      <th>ocean_proximity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-122.23</td>\n",
       "      <td>37.88</td>\n",
       "      <td>41.0</td>\n",
       "      <td>880.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>322.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>8.3252</td>\n",
       "      <td>452600.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-122.22</td>\n",
       "      <td>37.86</td>\n",
       "      <td>21.0</td>\n",
       "      <td>7099.0</td>\n",
       "      <td>1106.0</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>1138.0</td>\n",
       "      <td>8.3014</td>\n",
       "      <td>358500.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-122.24</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1467.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>496.0</td>\n",
       "      <td>177.0</td>\n",
       "      <td>7.2574</td>\n",
       "      <td>352100.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1274.0</td>\n",
       "      <td>235.0</td>\n",
       "      <td>558.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>5.6431</td>\n",
       "      <td>341300.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-122.25</td>\n",
       "      <td>37.85</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1627.0</td>\n",
       "      <td>280.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>259.0</td>\n",
       "      <td>3.8462</td>\n",
       "      <td>342200.0</td>\n",
       "      <td>NEAR BAY</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   longitude  latitude  housing_median_age  total_rooms  total_bedrooms  \\\n",
       "0    -122.23     37.88                41.0        880.0           129.0   \n",
       "1    -122.22     37.86                21.0       7099.0          1106.0   \n",
       "2    -122.24     37.85                52.0       1467.0           190.0   \n",
       "3    -122.25     37.85                52.0       1274.0           235.0   \n",
       "4    -122.25     37.85                52.0       1627.0           280.0   \n",
       "\n",
       "   population  households  median_income  median_house_value ocean_proximity  \n",
       "0       322.0       126.0         8.3252            452600.0        NEAR BAY  \n",
       "1      2401.0      1138.0         8.3014            358500.0        NEAR BAY  \n",
       "2       496.0       177.0         7.2574            352100.0        NEAR BAY  \n",
       "3       558.0       219.0         5.6431            341300.0        NEAR BAY  \n",
       "4       565.0       259.0         3.8462            342200.0        NEAR BAY  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('./datasets/housing.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 20640 entries, 0 to 20639\n",
      "Data columns (total 10 columns):\n",
      "longitude             20640 non-null float64\n",
      "latitude              20640 non-null float64\n",
      "housing_median_age    20640 non-null float64\n",
      "total_rooms           20640 non-null float64\n",
      "total_bedrooms        20433 non-null float64\n",
      "population            20640 non-null float64\n",
      "households            20640 non-null float64\n",
      "median_income         20640 non-null float64\n",
      "median_house_value    20640 non-null float64\n",
      "ocean_proximity       20640 non-null object\n",
      "dtypes: float64(9), object(1)\n",
      "memory usage: 1.6+ MB\n"
     ]
    }
   ],
   "source": [
    "# 存在缺失值，和非数值特征\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1H OCEAN     9136\n",
       "INLAND        6551\n",
       "NEAR OCEAN    2658\n",
       "NEAR BAY      2290\n",
       "ISLAND           5\n",
       "Name: ocean_proximity, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['ocean_proximity'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在预处理前，划分数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train_test_split(data, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据数量为14448, 测试数据数量为6192\n"
     ]
    }
   ],
   "source": [
    "print(\"训练数据数量为{}, 测试数据数量为{}\".format(len(X_train), len(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 保存数据的columns信息，以防止信息丢失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 因为用sklearn做preprocessing时，所有数据均为ndarray，所以需要确定特征所在位置\n",
    "class ColumnMapper(object):\n",
    "    def __init__(self, data:pd.DataFrame):\n",
    "        self.columns = data.columns.tolist()\n",
    "        self.indices = np.arange(len(self.columns)).tolist()\n",
    "    \n",
    "    def get_index(self, column_names:list):\n",
    "        return [self.indices[self.columns.index(item)] for item in column_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnmapper = ColumnMapper(data)\n",
    "columnmapper.get_index(['longitude', 'latitude'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 构造特征选择器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为整个pipeline的第一层，所以输入数据仍可保留columns信息以供特征的选择\n",
    "class DataFrameSelector(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, selected_attrs:list):\n",
    "        self.selected_attrs = selected_attrs\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X:pd.DataFrame):\n",
    "        return X[self.selected_attrs].values   # 返回ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 字符特征的预处理示例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "独热编码的列名为['x0_<1H OCEAN' 'x0_INLAND' 'x0_ISLAND' 'x0_NEAR BAY' 'x0_NEAR OCEAN']\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "onehotencoder = OneHotEncoder()\n",
    "result1 = onehotencoder.fit_transform(X_train[['ocean_proximity']]).toarray()\n",
    "print(\"独热编码的列名为{}\".format(onehotencoder.get_feature_names()))\n",
    "print(result1[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       [0., 1., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [0., 0., 0., 0., 1.],\n",
       "       [1., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 封装成流水线\n",
    "pipeline_str = Pipeline([('str_features', DataFrameSelector(['ocean_proximity'])), ('str_onehot', OneHotEncoder())])\n",
    "pipeline_str.fit_transform(X_train).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数值特征工程的自动化流水线示例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 缺失值的处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy='median')  # 中位数填充，返回值为ndarray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 特征组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**若新特征仅仅可以根据对应数据的各特征进行计算得到，则只需改写transform方法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据业务定制\n",
    "class FeaturesCombiner(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, add_bedroom=True):   # 超参数\n",
    "        self.add_bedroom = add_bedroom\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # 获取变换特征的绝对索引，以处理ndarray\n",
    "        rooms_ix, bedrooms_ix, population_ix, household_ix = columnmapper.get_index(['total_rooms','total_bedrooms','population','households'])\n",
    "        rooms_per_household = X[:, rooms_ix] / X[:, household_ix]\n",
    "        population_per_household = X[:, population_ix] / X[:, household_ix]\n",
    "        if self.add_bedroom:\n",
    "            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "            return np.c_[X, rooms_per_household, population_per_household, bedrooms_per_room]\n",
    "        else:\n",
    "            return np.c_[X, rooms_per_household, population_per_household]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-117.81      ,   33.56      ,   24.        , ...,    8.32180851,\n",
       "           2.30053191,    0.16027485],\n",
       "       [-121.49      ,   37.94      ,   31.        , ...,    6.34812287,\n",
       "           6.30716724,    0.21182796],\n",
       "       [-119.84      ,   36.79      ,   21.        , ...,    5.26872964,\n",
       "           2.96416938,    0.20030912],\n",
       "       ...,\n",
       "       [-119.82      ,   34.45      ,   24.        , ...,    6.8030303 ,\n",
       "           3.1875    ,    0.1483853 ],\n",
       "       [-120.82      ,   35.31      ,   16.        , ...,    6.15047022,\n",
       "           2.07680251,    0.17813456],\n",
       "       [-118.47      ,   34.01      ,   41.        , ...,    3.63285024,\n",
       "           2.32850242,    0.26728723]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featurescombiner = FeaturesCombiner()\n",
    "featurescombiner.fit_transform(X_train.drop('ocean_proximity', axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**若测试集上的新特征要利用训练集上的保留结果，则需改写fit和transform方法**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据业务定制\n",
    "class FeaturesMaker(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):   # 超参数\n",
    "        self.mean_ = None\n",
    "        self.std_ = None\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        self.medain_income_ix = columnmapper.get_index(['median_income'])[0]\n",
    "        self.mean_ = X[:, self.medain_income_ix].mean()\n",
    "        self.std_ = X[:, self.medain_income_ix].std()\n",
    "        return self                                          \n",
    "                                                  \n",
    "    def transform(self, X):\n",
    "        if not self.mean_ or not self.std_:\n",
    "            raise(\"还未fit\")\n",
    "        X[:, self.medain_income_ix] = (X[:, self.medain_income_ix]-self.mean_)/np.sqrt(self.std_)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.17810000e+02,  3.35600000e+01,  2.40000000e+01, ...,\n",
       "         7.52000000e+02,  5.12943521e+00,  5.00001000e+05],\n",
       "       [-1.21490000e+02,  3.79400000e+01,  3.10000000e+01, ...,\n",
       "         2.93000000e+02, -1.14908918e+00,  1.62500000e+05],\n",
       "       [-1.19840000e+02,  3.67900000e+01,  2.10000000e+01, ...,\n",
       "         6.14000000e+02, -3.84747077e-01,  7.14000000e+04],\n",
       "       ...,\n",
       "       [-1.19820000e+02,  3.44500000e+01,  2.40000000e+01, ...,\n",
       "         5.28000000e+02,  2.06265373e+00,  3.33800000e+05],\n",
       "       [-1.20820000e+02,  3.53100000e+01,  1.60000000e+01, ...,\n",
       "         6.38000000e+02, -9.83925826e-01,  2.93900000e+05],\n",
       "       [-1.18470000e+02,  3.40100000e+01,  4.10000000e+01, ...,\n",
       "         2.07000000e+02, -9.66185790e-01,  4.18200000e+05]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_copy = X_train.copy()\n",
    "fm = FeaturesMaker()\n",
    "fm.fit_transform(X_train_copy.drop('ocean_proximity', axis=1).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 标准化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 整合流水线"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 封装成流水线\n",
    "# 有一点需要注意，当特征存在删除和减少时，特征的位置有可能发生变化，因此需要注意\n",
    "num_features = X_train.columns.tolist()\n",
    "num_features.remove('ocean_proximity')\n",
    "pipeline_num = Pipeline([('num_features', DataFrameSelector(num_features)), ('add_attrs', FeaturesCombiner()), \n",
    "                         ('partial_fit_atts', FeaturesMaker()), ('std', StandardScaler())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_results = pipeline_num.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14448, 12)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_results.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 在多组pipeline的基础上进行特征的合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=[('str_pipeline', pipeline_str), ('num_pipeline', pipeline_num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results = full_pipeline.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14448, 17)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('str_pipeline', Pipeline(memory=None,\n",
       "       steps=[('str_features', DataFrameSelector(selected_attrs=['ocean_proximity'])), ('str_onehot', OneHotEncoder(categorical_features=None, categories=None,\n",
       "         dtype=<class 'numpy.float64'>, handle_unknown='error',\n",
       "         n_values=None, sparse=True))])),\n",
       " ('num_pipeline', Pipeline(memory=None,\n",
       "       steps=[('num_features', DataFrameSelector(selected_attrs=['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income', 'median_house_value'])), ('add_attrs', FeaturesCombiner(add_bedroom=True)), ('partial_fit_atts', FeaturesMaker()), ('std', StandardScaler(copy=True, with_mean=True, with_std=True))]))]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pipeline.transformer_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 将该特征工程直接作用于测试数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_text = full_pipeline.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6192, 17)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_results_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 可以将预处理和模型学习整合为一个pipeline，一同进行gridserchcv寻找最优的预训练超参数和模型超参数组合"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "预测房价median_house_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 去定标签所在列\n",
    "columnmapper.get_index(['median_house_value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_copy = X_train.copy()\n",
    "X_test_copy = X_test.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将x和y进行分离\n",
    "X_train_2 , y_train_2 = X_train_copy.drop(columns='median_house_value'), X_train_copy[['median_house_value']]\n",
    "X_test_2 , y_test_2 = X_test_copy.drop(columns='median_house_value'), X_test_copy[['median_house_value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['longitude',\n",
       " 'latitude',\n",
       " 'housing_median_age',\n",
       " 'total_rooms',\n",
       " 'total_bedrooms',\n",
       " 'population',\n",
       " 'households',\n",
       " 'median_income']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X特征定义\n",
    "num_features2 = X_train_2.columns.tolist()\n",
    "num_features2.remove('ocean_proximity')\n",
    "num_features2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预处理的pipeline封装\n",
    "pipeline4str = Pipeline([('str_features', DataFrameSelector(['ocean_proximity'])), ('str_onehot', OneHotEncoder())])\n",
    "pipeline4num = Pipeline([('num_features', DataFrameSelector(num_features2)), ('imputer', SimpleImputer()), ('add_attrs', FeaturesCombiner()), \n",
    "                         ('partial_fit_atts', FeaturesMaker()), ('std', StandardScaler())])\n",
    "full_pipeline = FeatureUnion(transformer_list=[('str_pipeline', pipeline4str), ('num_pipeline', pipeline4num)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RF模型\n",
    "rf = RandomForestRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 将预处理器和估计器再封装为一个pipeline\n",
    "overall_pipeline = Pipeline([('preprocess', full_pipeline), ('learn', rf)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网格搜索超参数\n",
    "grid_params = {'preprocess__num_pipeline__imputer__strategy':['mean', 'median'], \n",
    "              'preprocess__num_pipeline__add_attrs__add_bedroom':[True, False],'learn__n_estimators':range(10,100,10)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('preprocess', FeatureUnion(n_jobs=None,\n",
       "       transformer_list=[('str_pipeline', Pipeline(memory=None,\n",
       "     steps=[('str_features', DataFrameSelector(selected_attrs=['ocean_proximity'])), ('str_onehot', OneHotEncoder(categorical_features=None, categories=None,\n",
       "       dtype=<class 'numpy.flo...s='warn', n_jobs=None,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'preprocess__num_pipeline__imputer__strategy': ['mean', 'median'], 'preprocess__num_pipeline__add_attrs__add_bedroom': [True, False], 'learn__n_estimators': range(10, 100, 10)},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GridSearchCV(overall_pipeline, param_grid=grid_params, cv=5)\n",
    "clf.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learn__n_estimators': 90,\n",
       " 'preprocess__num_pipeline__add_attrs__add_bedroom': True,\n",
       " 'preprocess__num_pipeline__imputer__strategy': 'mean'}"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
